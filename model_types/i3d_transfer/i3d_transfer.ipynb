{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and TF-Hub modules.\n",
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "# from tensorflow_docs.vis import embed\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# Some modules to help with reading the UCF101 dataset.\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "from urllib import request  # requires python3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.src.applications.xception import Xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities to fetch videos from UCF101 dataset\n",
    "UCF_ROOT = \"https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/\"\n",
    "_VIDEO_LIST = None\n",
    "_CACHE_DIR = tempfile.mkdtemp()\n",
    "# As of July 2020, crcv.ucf.edu doesn't use a certificate accepted by the\n",
    "# default Colab environment anymore.\n",
    "unverified_context = ssl._create_unverified_context()\n",
    "\n",
    "\n",
    "def list_ucf_videos():\n",
    "  \"\"\"Lists videos available in UCF101 dataset.\"\"\"\n",
    "  global _VIDEO_LIST\n",
    "  if not _VIDEO_LIST:\n",
    "    index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode(\"utf-8\")\n",
    "    videos = re.findall(\"(v_[\\w_]+\\.avi)\", index)\n",
    "    _VIDEO_LIST = sorted(set(videos))\n",
    "  return list(_VIDEO_LIST)\n",
    "\n",
    "\n",
    "def fetch_ucf_video(video):\n",
    "  \"\"\"Fetches a video and cache into local filesystem.\"\"\"\n",
    "  cache_path = os.path.join(_CACHE_DIR, video)\n",
    "  if not os.path.exists(cache_path):\n",
    "    urlpath = request.urljoin(UCF_ROOT, video)\n",
    "    print(\"Fetching %s => %s\" % (urlpath, cache_path))\n",
    "    data = request.urlopen(urlpath, context=unverified_context).read()\n",
    "    open(cache_path, \"wb\").write(data)\n",
    "  return cache_path\n",
    "\n",
    "\n",
    "# Utilities to open video files using CV2\n",
    "def crop_center_square(frame):\n",
    "  y, x = frame.shape[0:2]\n",
    "  min_dim = min(y, x)\n",
    "  start_x = (x // 2) - (min_dim // 2)\n",
    "  start_y = (y // 2) - (min_dim // 2)\n",
    "  return frame[start_y:start_y+min_dim,start_x:start_x+min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=20, resize=(224, 224)):\n",
    "  cap = cv2.VideoCapture(path)\n",
    "  frames = []\n",
    "  try:\n",
    "    while cap.isOpened():\n",
    "      ret, frame = cap.read()\n",
    "      if not ret:\n",
    "        break\n",
    "      \n",
    "      frame = crop_center_square(frame)\n",
    "      frame = cv2.resize(frame, resize)\n",
    "      frame = frame[:, :, [2, 1, 0]]\n",
    "\n",
    "      frame = datagen.random_transform(frame)  # Augment each frame\n",
    "\n",
    "      frames.append(frame)\n",
    "\n",
    "      if len(frames) == max_frames:\n",
    "        break\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < max_frames:\n",
    "        frames += [np.zeros_like(frames[0])] * (max_frames - len(frames))\n",
    "    \n",
    "  except Exception as e:\n",
    "     print(e)\n",
    "      \n",
    "  return np.array(frames) / 255.0\n",
    "\n",
    "\n",
    "# def video_to_frames(video_path, img_size, sequence_length):\n",
    "#     cap = cv2.VideoCapture(video_path)\n",
    "#     frames = []\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         frame = cv2.resize(frame, img_size)\n",
    "#         frames.append(frame)\n",
    "#         if len(frames) == sequence_length:\n",
    "#             break\n",
    "#     cap.release()\n",
    "\n",
    "#     if len(frames) < sequence_length:\n",
    "#         return None  # Ignore short videos\n",
    "\n",
    "#     return np.array(frames)\n",
    "\n",
    "\n",
    "def to_gif(images):\n",
    "  converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "  gif = imageio.mimsave('./animation.gif', converted_images, duration=40)\n",
    "  return gif\n",
    "\n",
    "\n",
    "# List files and ignore .DS_Store if on a Mac\n",
    "def list_files(directory):\n",
    "    visible_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if not file.startswith('.'):\n",
    "            visible_files.append(file)\n",
    "\n",
    "    return visible_files\n",
    "\n",
    "\n",
    "def video_to_frames(video_path, img_size=(64, 64), sequence_length=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # frame = cv2.resize(frame, img_size)\n",
    "        img = keras.utils.load_img(frame, target_size=(224, 224))\n",
    "        x = keras.utils.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        frames.append(x)\n",
    "        if len(frames) == sequence_length:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < sequence_length:\n",
    "        return None  # Ignore short videos\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "# Get paths and labels\n",
    "def load_dataset(folder_path, print_path=False):\n",
    "    # classes = os.listdir(folder_path)\n",
    "    classes = list_files(folder_path)\n",
    "    paths, true_labels, activities = [], [], []\n",
    "\n",
    "    for label, activity in enumerate(classes):\n",
    "        activity_folder = os.path.join(folder_path, activity)\n",
    "        files = list_files(activity_folder)\n",
    "        num_files = len(files)\n",
    "        current = 1\n",
    "        for video_file in files:\n",
    "            video_path = os.path.join(activity_folder, video_file)\n",
    "            paths.append(video_path)\n",
    "            true_labels.append(label)\n",
    "            activities.append(activity)\n",
    "\n",
    "            if print_path:\n",
    "                print(f'{current}/{num_files}\\t{video_path}')\n",
    "\n",
    "            current += 1\n",
    "\n",
    "    return paths, true_labels, activities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 12\n",
    "\n",
    "# Augmentations\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(print_details=True):\n",
    "    # Load i3d-kinetics-400 model\n",
    "    i3d = hub.load(\"https://tfhub.dev/deepmind/i3d-kinetics-400/1\").signatures['default']\n",
    "\n",
    "    class I3DModelLayer(tf.keras.layers.Layer):\n",
    "        def __init__(self, i3d_model):\n",
    "            super(I3DModelLayer, self).__init__()\n",
    "            self.i3d_model = i3d_model\n",
    "\n",
    "        def call(self, inputs):\n",
    "            output = self.i3d_model(rgb_input=inputs)['default']\n",
    "            return output\n",
    "        \n",
    "    # Freeze layers\n",
    "    i3d.trainable = False\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(20, 224, 224, 3))\n",
    "    i3d_layer = I3DModelLayer(i3d)\n",
    "    x = i3d_layer(inputs) \n",
    "    # print(f\"Shape after I3DLayer: {x.shape}\")\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    outputs = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    if print_details:\n",
    "        model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths and labels\n",
    "def load_dataset(folder_path, print_path=False):\n",
    "    # classes = os.listdir(folder_path)\n",
    "    classes = list_files(folder_path)\n",
    "    paths, true_labels, activities = [], [], []\n",
    "\n",
    "    for label, activity in enumerate(classes):\n",
    "        activity_folder = os.path.join(folder_path, activity)\n",
    "        files = list_files(activity_folder)\n",
    "        num_files = len(files)\n",
    "        current = 1\n",
    "        for video_file in files:\n",
    "            video_path = os.path.join(activity_folder, video_file)\n",
    "            paths.append(video_path)\n",
    "            true_labels.append(label)\n",
    "            activities.append(activity)\n",
    "\n",
    "            if print_path:\n",
    "                print(f'{current}/{num_files}\\t{video_path}')\n",
    "\n",
    "            current += 1\n",
    "\n",
    "    return paths, true_labels, activities\n",
    "\n",
    "\n",
    "def make_dataset(paths, labels):\n",
    "    all_data = []\n",
    "    all_labels = []\n",
    "\n",
    "    for p in enumerate(paths): \n",
    "        print(f'{p[0] + 1}/{len(paths)}\\t{p[1]}')\n",
    "        frames = load_video(p[1])\n",
    "        all_data.append(frames)\n",
    "        lab = labels[p[0]]\n",
    "        all_labels.append(lab)\n",
    "\n",
    "    return all_data, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = f\"../../downloads/fr_10s/train_fr_10s\"\n",
    "train_paths, train_labels, train_activities = load_dataset(train_dir)\n",
    "\n",
    "test_dir = f\"../../downloads/fr_10s/test_fr_10s\"\n",
    "test_paths, test_labels, test_activities = load_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = make_dataset(train_paths, train_labels)\n",
    "X_test, y_test = make_dataset(test_paths, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(\n",
    "    lambda epoch: 0.0001 * 10 ** (epoch / 10)\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Build model\n",
    "model = built_model(print_details=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=10,\n",
    "                    validation_split=0.2, \n",
    "                    callbacks=[early_stopping, lr_schedule])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
