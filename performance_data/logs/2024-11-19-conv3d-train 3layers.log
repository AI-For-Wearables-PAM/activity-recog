Testing with parameters: {'conv_filters': [32, 64, 128], 'kernel_size': (3, 3, 3), 'dense_units': 512, 'dropout_rate': 0.4, 'learning_rate': 0.001, 'batch_size': 8, 'epochs': 15}

Iteration 1/3
C:\Users\james\.conda\envs\recog\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
2024-11-19 04:29:41.822186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 36s 304ms/step - accuracy: 0.3552 - loss: 7.0491 - val_accuracy: 0.0395 - val_loss: 14.2606
Epoch 2/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.5519 - loss: 1.3103 - val_accuracy: 0.3553 - val_loss: 1.6776
Epoch 3/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.6354 - loss: 1.0927 - val_accuracy: 0.7368 - val_loss: 0.9421
Epoch 4/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.6599 - loss: 0.9374 - val_accuracy: 0.7544 - val_loss: 0.7535
Epoch 5/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7159 - loss: 0.8470 - val_accuracy: 0.6579 - val_loss: 1.2218
Epoch 6/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.6867 - loss: 0.8972 - val_accuracy: 0.7675 - val_loss: 0.7623
Epoch 7/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7230 - loss: 0.7995 - val_accuracy: 0.7544 - val_loss: 0.5784
Epoch 8/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7086 - loss: 0.7921 - val_accuracy: 0.6974 - val_loss: 0.7099
Epoch 9/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7577 - loss: 0.6468 - val_accuracy: 0.8202 - val_loss: 0.5636
Epoch 10/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7656 - loss: 0.6795 - val_accuracy: 0.7763 - val_loss: 0.6142
Epoch 11/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7817 - loss: 0.5999 - val_accuracy: 0.7719 - val_loss: 0.5825
Epoch 12/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7445 - loss: 0.7775 - val_accuracy: 0.5877 - val_loss: 1.0843
Epoch 13/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.7353 - loss: 0.6975 - val_accuracy: 0.7632 - val_loss: 0.5575
Epoch 14/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 35s 305ms/step - accuracy: 0.8030 - loss: 0.5330 - val_accuracy: 0.7895 - val_loss: 0.4986
Epoch 15/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.8102 - loss: 0.5694 - val_accuracy: 0.8026 - val_loss: 0.5828
8/8 ━━━━━━━━━━━━━━━━━━━━ 2s 176ms/step
Iteration 1 Validation Accuracy: 0.8026315789473685
Best model saved with accuracy 0.8026315789473685

Iteration 2/3
C:\Users\james\.conda\envs\recog\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Epoch 1/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 36s 305ms/step - accuracy: 0.3826 - loss: 5.5427 - val_accuracy: 0.2632 - val_loss: 4.9862
Epoch 2/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.4892 - loss: 1.9790 - val_accuracy: 0.5570 - val_loss: 1.6066
Epoch 3/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.6167 - loss: 1.1370 - val_accuracy: 0.6754 - val_loss: 1.0266
Epoch 4/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.6638 - loss: 0.9675 - val_accuracy: 0.5395 - val_loss: 1.2448
Epoch 5/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.6873 - loss: 0.8682 - val_accuracy: 0.4430 - val_loss: 1.4638
Epoch 6/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.6696 - loss: 1.0050 - val_accuracy: 0.7193 - val_loss: 0.7126
Epoch 7/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7370 - loss: 0.7047 - val_accuracy: 0.7675 - val_loss: 0.6899
Epoch 8/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7380 - loss: 0.7127 - val_accuracy: 0.8114 - val_loss: 0.4965
Epoch 9/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7320 - loss: 0.7440 - val_accuracy: 0.6667 - val_loss: 0.8413
Epoch 10/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7415 - loss: 0.8225 - val_accuracy: 0.6009 - val_loss: 1.0102
Epoch 11/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7206 - loss: 0.8529 - val_accuracy: 0.6184 - val_loss: 1.1878
Epoch 12/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7895 - loss: 0.6126 - val_accuracy: 0.8377 - val_loss: 0.4192
Epoch 13/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.8313 - loss: 0.4920 - val_accuracy: 0.8596 - val_loss: 0.4524
Epoch 14/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.8331 - loss: 0.4654 - val_accuracy: 0.8026 - val_loss: 0.5591
Epoch 15/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.8331 - loss: 0.4987 - val_accuracy: 0.5614 - val_loss: 2.0671
8/8 ━━━━━━━━━━━━━━━━━━━━ 2s 176ms/step
Iteration 2 Validation Accuracy: 0.5614035087719298

Iteration 3/3
C:\Users\james\.conda\envs\recog\Lib\site-packages\keras\src\layers\convolutional\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
  super().__init__(activity_regularizer=activity_regularizer, **kwargs)
Epoch 1/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 36s 304ms/step - accuracy: 0.3756 - loss: 6.6372 - val_accuracy: 0.3509 - val_loss: 5.1378
Epoch 2/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.5800 - loss: 1.3936 - val_accuracy: 0.7456 - val_loss: 0.6606
Epoch 3/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7054 - loss: 0.8967 - val_accuracy: 0.7544 - val_loss: 0.8519
Epoch 4/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 301ms/step - accuracy: 0.6802 - loss: 1.0134 - val_accuracy: 0.7281 - val_loss: 0.8417
Epoch 5/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7349 - loss: 0.8361 - val_accuracy: 0.7193 - val_loss: 0.7970
Epoch 6/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7246 - loss: 0.7295 - val_accuracy: 0.7368 - val_loss: 0.6447
Epoch 7/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7398 - loss: 0.7127 - val_accuracy: 0.8026 - val_loss: 0.5376
Epoch 8/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7412 - loss: 0.6703 - val_accuracy: 0.7807 - val_loss: 0.5756
Epoch 9/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7495 - loss: 0.7918 - val_accuracy: 0.7763 - val_loss: 0.5360
Epoch 10/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7785 - loss: 0.5993 - val_accuracy: 0.8158 - val_loss: 0.5264
Epoch 11/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.8043 - loss: 0.5169 - val_accuracy: 0.7544 - val_loss: 0.6410
Epoch 12/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7993 - loss: 0.5804 - val_accuracy: 0.7588 - val_loss: 0.7007
Epoch 13/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.7727 - loss: 0.6184 - val_accuracy: 0.6579 - val_loss: 0.9160
Epoch 14/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 35s 303ms/step - accuracy: 0.7990 - loss: 0.5893 - val_accuracy: 0.8509 - val_loss: 0.4306
Epoch 15/15
114/114 ━━━━━━━━━━━━━━━━━━━━ 34s 302ms/step - accuracy: 0.8079 - loss: 0.5815 - val_accuracy: 0.7193 - val_loss: 0.8009
WARNING:tensorflow:5 out of the last 17 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001AD28076660> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.
8/8 ━━━━━━━━━━━━━━━━━━━━ 1s 175ms/step
Iteration 3 Validation Accuracy: 0.7192982456140351

Best hyperparameters: {'conv_filters': [32, 64, 128], 'kernel_size': (3, 3, 3), 'dense_units': 512, 'dropout_rate': 0.4, 'learning_rate': 0.001, 'batch_size': 8, 'epochs': 15} with accuracy: 0.8026315789473685
True labels: [ 5  0  6  7  4  6  5 11  6  4  5 11  0 11  6 11  5 11  0  9 11  5  0  5
  5  2  0  7  7  2  2  3 11  0  4  9  7  8  5  3 11  0  9  2 11  6  6  6
  7 10  0  6  5  7  5 11  7  9  4  0 11  2  5 11  7  8 11 11  7  6 11 11
  0  2  0  7  0 11  7  6  0  7 11 11  2  2  2  0  7  8  2  0  2  5  5  3
 11  9  0 11  3 11  0  5  0  0 11  5  2  0  7  6  6 11  7 11  2  7 11  2
  0  0 11  8 11  0  0  2  4  0 11  0  0  6 11  8  5  6  6  5  6  8  0  4
  7  5  2  0  0  7 10  5  2  3  0  6  2  7 11  3  5 11  0  0 11  6  2  2
  3  2  5  0  0  5  0  9  3  5  0  8  4  5  4  6  7  5 10  1  5  5  0  2
  1 10  8  6 11  0  3 11  0  7  0  6  5  5  0  8  2 11 11  0  0  2  0  0
  2  0  7  9 11  7  6  5 11 11 11  6]
Predicted labels: [ 5  0  6  7  4  2  5 11  6  4  5 11  0 11  6 10  5 11  0  9 11  5  0  5
 10  2  0  7  7  2  2  3 11  5  4  9  7  8  0 11 11  0  9  2 11  6  6  6
  7 10  0  2  5  7  0 11  7  9  4  5 11  2  0 11  7  7 11 11  7  6 11 11
  0  2  0  7  0 10  7  6  0  7 11 11  2  2  2  0  7  8  2  6  2  0  5  3
 10  9  0 11  3 11  5  5  6  0 11  0  2  0  7  6  5 11  7 11  2  7  2  2
  8  9 11  8 11  0  0  2  4  4 11  0  5  6 11  8  5  6  6  5  6  8  0  4
  7  0  2  5  0  7  4  5  2  3  0  0  2  7 11 11  0 10  0  0 11  0  2  2
 11  2  5  0  0  0  0  9  3  5  4  8  4  5  4  6  7  5  4 10  0  5  5  2
 10  4  8  6 11  0 11 11  0  7  0  6  5  5  0  8  2 11 11  0  0  2  5  0
  2  5  7  9 11  7 11  5 11 11 11  6]
Done
{'conv_filters': [32, 64, 128], 'kernel_size': (3, 3, 3), 'dense_units': 512, 'dropout_rate': 0.4, 'learning_rate': 0.001, 'batch_size': 8, 'epochs': 15}
0.8026315789473685
2024-11-19-04-38-21-conv3d-model.keras