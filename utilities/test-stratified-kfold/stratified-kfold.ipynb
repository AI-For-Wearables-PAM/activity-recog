{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stratified k-fold cross validation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "Fold 0:\n",
      "  Train: index=[1 3]\n",
      "  Test:  index=[0 2]\n",
      "Fold 1:\n",
      "  Train: index=[0 2]\n",
      "  Test:  index=[1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using stratified kfold on the digits dataset\n",
    "- Source: https://github.com/codebasics/py/blob/master/ML/12_KFold_Cross_Validation/12_k_fold.ipynb\n",
    "- Video tutorial: https://www.youtube.com/watch?v=gJo0uNL-5Qw  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "# Function to train model and return prediction score.\n",
    "# The scores are all mean accuracy except MLP regressor, which uses R^2\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Load handwritten digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Format X and y as np arrays\n",
    "X = digits.data  # X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = digits.target   # y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Configure StratifiedKFold\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_mlp = []\n",
    "scores_mlp_regressor = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}\")\n",
    "    # print(f\"  Train: index={train_index}\")\n",
    "    # print(f\"  Test:  index={test_index}\")\n",
    "   \n",
    "    # Train LogisticRegression\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train SVC\n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train RandomForestClassifier\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLP\n",
    "    scores_mlp.append(get_score(MLPClassifier(random_state=1, max_iter=300), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLPRegressor (this one is slow)\n",
    "    scores_mlp_regressor.append(get_score(MLPRegressor(random_state=1, max_iter=500), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "\n",
    "# Print all scores\n",
    "model_names = [\"LogisticRegression\", \"SVC\", \"RandomForestClassifier\", \"MLPClassifier\", \"MLPRegressor\"]\n",
    "scores = [scores_logistic, scores_svm, scores_rf, scores_mlp, scores_mlp_regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.454039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.448468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.479109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.896936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Fold     Score\n",
       "0       LogisticRegression     0  0.922222\n",
       "1       LogisticRegression     0  0.411111\n",
       "2       LogisticRegression     0  0.938889\n",
       "3       LogisticRegression     0  0.947222\n",
       "4       LogisticRegression     0  0.826025\n",
       "5                      SVC     1  0.883333\n",
       "6                      SVC     1  0.450000\n",
       "7                      SVC     1  0.880556\n",
       "8                      SVC     1  0.877778\n",
       "9                      SVC     1  0.809039\n",
       "10  RandomForestClassifier     2  0.952646\n",
       "11  RandomForestClassifier     2  0.454039\n",
       "12  RandomForestClassifier     2  0.955432\n",
       "13  RandomForestClassifier     2  0.972145\n",
       "14  RandomForestClassifier     2  0.789852\n",
       "15           MLPClassifier     3  0.958217\n",
       "16           MLPClassifier     3  0.448468\n",
       "17           MLPClassifier     3  0.958217\n",
       "18           MLPClassifier     3  0.961003\n",
       "19           MLPClassifier     3  0.865563\n",
       "20            MLPRegressor     4  0.894150\n",
       "21            MLPRegressor     4  0.479109\n",
       "22            MLPRegressor     4  0.922006\n",
       "23            MLPRegressor     4  0.896936\n",
       "24            MLPRegressor     4  0.783802"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare model performance\n",
    "all_models = []\n",
    "all_folds = []\n",
    "all_scores = []\n",
    "\n",
    "for i in enumerate(model_names):\n",
    "    for s in scores:\n",
    "        all_models.append(i[1])\n",
    "        all_folds.append(i[0])\n",
    "        all_scores.append(s[i[0]])\n",
    "\n",
    "# Make DataFrame of results\n",
    "data = {\"Model\": all_models, \"Fold\": all_folds, \"Score\": all_scores}\n",
    "scores_df = pd.DataFrame(data)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify ImageNet classes with ResNet50\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# # decode the results into a list of tuples (class, description, probability)\n",
    "# # (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicing Video frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The video preprocessing method here may be useful\n",
    "\n",
    "Tutorial: https://keras.io/examples/vision/video_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, img_size=(64, 64), sequence_length=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # frame = cv2.resize(frame, img_size)\n",
    "        img = keras.utils.load_img(frame, target_size=(224, 224))\n",
    "        x = keras.utils.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        frames.append(x)\n",
    "        if len(frames) == sequence_length:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < sequence_length:\n",
    "        return None  # Ignore short videos\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a CSV with video filenames and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files and ignore .DS_Store if on a Mac\n",
    "def list_files(directory):\n",
    "    visible_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if not file.startswith('.'):\n",
    "            visible_files.append(file)\n",
    "\n",
    "    return visible_files\n",
    "\n",
    "def catalog_videos(folder_path):\n",
    "    # classes = os.listdir(folder_path)\n",
    "    classes = list_files(folder_path)\n",
    "    videos, labels, encoded_labels, paths = [], [], [], []\n",
    "\n",
    "    for label, activity in enumerate(classes):\n",
    "        activity_folder = os.path.join(folder_path, activity)\n",
    "        # for video_file in os.listdir(activity_folder):\n",
    "        for video_file in list_files(activity_folder):\n",
    "            video_path = os.path.join(activity_folder, video_file)\n",
    "            videos.append(video_file)\n",
    "            labels.append(activity)\n",
    "            encoded_labels.append(label)\n",
    "            paths.append(video_path)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    le.transform(labels)\n",
    "\n",
    "    return videos, labels, encoded_labels, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catalog_csv(path, name):\n",
    "    # Create catalog of dataset details\n",
    "    catalog = catalog_videos(path)\n",
    "\n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame({'video': catalog[0], 'label': catalog[1],\n",
    "                            'encoded_label': catalog[2], 'path': catalog[3]})\n",
    "    # Export CSV\n",
    "    filename = f'{name}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f'Saved to {filename}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to train_df.csv\n",
      "Saved to test_df.csv\n"
     ]
    }
   ],
   "source": [
    "# Make CSV for training/testing sets\n",
    "# train_path = \"../../downloads/old_clips/full_res/train\"\n",
    "# test_path = \"../../downloads/old_clips/full_res/test\"\n",
    "train_path = \"../../downloads/fr_10s/train_fr_10s\"\n",
    "test_path = \"../../downloads/fr_10s/test_fr_10s\"\n",
    "\n",
    "train_df = make_catalog_csv(train_path, \"train_df\")\n",
    "test_df = make_catalog_csv(test_path, \"test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7394376363047963793_s_5.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/EVS Visit/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7393498639236385937_s_10.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/EVS Visit/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7394377634358283409_s_2.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/EVS Visit/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7394377634358283409_s_3.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/EVS Visit/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7393498639236385937_s_11.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/EVS Visit/7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>7393795537440656529_s_6.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/Nurse Visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>7393762504847182993_s_4.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/Nurse Visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>7393723729882434705_s_9.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/Nurse Visit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>7393435193979489425_s_10.mp4</td>\n",
       "      <td>Transfer To Bed</td>\n",
       "      <td>11</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/Transfer To...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>7393435193979489425_s_9.mp4</td>\n",
       "      <td>Transfer To Bed</td>\n",
       "      <td>11</td>\n",
       "      <td>../../downloads/fr_10s/test_fr_10s/Transfer To...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1106 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             video            label  encoded_label  \\\n",
       "0      7394376363047963793_s_5.mp4        EVS Visit              0   \n",
       "1     7393498639236385937_s_10.mp4        EVS Visit              0   \n",
       "2      7394377634358283409_s_2.mp4        EVS Visit              0   \n",
       "3      7394377634358283409_s_3.mp4        EVS Visit              0   \n",
       "4     7393498639236385937_s_11.mp4        EVS Visit              0   \n",
       "...                            ...              ...            ...   \n",
       "1101   7393795537440656529_s_6.mp4      Nurse Visit             10   \n",
       "1102   7393762504847182993_s_4.mp4      Nurse Visit             10   \n",
       "1103   7393723729882434705_s_9.mp4      Nurse Visit             10   \n",
       "1104  7393435193979489425_s_10.mp4  Transfer To Bed             11   \n",
       "1105   7393435193979489425_s_9.mp4  Transfer To Bed             11   \n",
       "\n",
       "                                                   path  \n",
       "0     ../../downloads/fr_10s/test_fr_10s/EVS Visit/7...  \n",
       "1     ../../downloads/fr_10s/test_fr_10s/EVS Visit/7...  \n",
       "2     ../../downloads/fr_10s/test_fr_10s/EVS Visit/7...  \n",
       "3     ../../downloads/fr_10s/test_fr_10s/EVS Visit/7...  \n",
       "4     ../../downloads/fr_10s/test_fr_10s/EVS Visit/7...  \n",
       "...                                                 ...  \n",
       "1101  ../../downloads/fr_10s/test_fr_10s/Nurse Visit...  \n",
       "1102  ../../downloads/fr_10s/test_fr_10s/Nurse Visit...  \n",
       "1103  ../../downloads/fr_10s/test_fr_10s/Nurse Visit...  \n",
       "1104  ../../downloads/fr_10s/test_fr_10s/Transfer To...  \n",
       "1105  ../../downloads/fr_10s/test_fr_10s/Transfer To...  \n",
       "\n",
       "[1106 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asleep-Trying to sleep', 'Doctor Visit', 'EVS Visit', 'Eating', 'Family', 'Lying In Bed', 'Nurse Visit', 'Sitting In Wheelchair', 'Talking on the Phone', 'Therapy', 'Transfer To Bed', 'Watching TV']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"label\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is computationally intensive and may crash the kernel. Example error message:\n",
    "```\n",
    "The Kernel crashed while executing code in the current cell or a previous cell. \n",
    "Please review the code in the cell(s) to identify a possible cause of the failure. \n",
    "Click here for more info. \n",
    "View Jupyter log for further details.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[126], line 53\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (frame_features, frame_masks), labels\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Use paths declared earlier\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# train_path = \"../../downloads/old_clips/full_res/train\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# test_path = \"../../downloads/old_clips/full_res/test\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m prepare_all_videos(train_df, train_path)\n\u001b[1;32m     54\u001b[0m test_data, test_labels \u001b[38;5;241m=\u001b[39m prepare_all_videos(test_df, test_path)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrame features in train set: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[126], line 39\u001b[0m, in \u001b[0;36mprepare_all_videos\u001b[0;34m(df, root_dir)\u001b[0m\n\u001b[1;32m     37\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(MAX_SEQ_LENGTH, video_length)\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(length):\n\u001b[0;32m---> 39\u001b[0m         temp_frame_features[i, j, :] \u001b[38;5;241m=\u001b[39m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m     40\u001b[0m             batch[\u001b[38;5;28;01mNone\u001b[39;00m, j, :], verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     41\u001b[0m         )\n\u001b[1;32m     42\u001b[0m     temp_frame_mask[i, :length] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# 1 = not masked, 0 = masked\u001b[39;00m\n\u001b[1;32m     44\u001b[0m frame_features[idx,] \u001b[38;5;241m=\u001b[39m temp_frame_features\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:508\u001b[0m, in \u001b[0;36mTensorFlowTrainer.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    506\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[1;32m    507\u001b[0m data \u001b[38;5;241m=\u001b[39m get_data(iterator)\n\u001b[0;32m--> 508\u001b[0m batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict_function(data)\n\u001b[1;32m    509\u001b[0m outputs \u001b[38;5;241m=\u001b[39m append_to_outputs(batch_outputs, outputs)\n\u001b[1;32m    510\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_end(step, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: batch_outputs})\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m tracing_compilation\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m function\u001b[38;5;241m.\u001b[39m_call_flat(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[38;5;241m=\u001b[39mfunction\u001b[38;5;241m.\u001b[39mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inference_function\u001b[38;5;241m.\u001b[39mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcall_flat(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    253\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   1553\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1554\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   1555\u001b[0m       inputs\u001b[38;5;241m=\u001b[39mtensor_inputs,\n\u001b[1;32m   1556\u001b[0m       attrs\u001b[38;5;241m=\u001b[39mattrs,\n\u001b[1;32m   1557\u001b[0m       ctx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1558\u001b[0m   )\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"path\"].values.tolist()\n",
    "    labels = df[\"label\"].values\n",
    "    labels = keras.ops.convert_to_numpy(label_processor(labels[..., None]))\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        # frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = load_video(path)\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(\n",
    "            shape=(\n",
    "                1,\n",
    "                MAX_SEQ_LENGTH,\n",
    "            ),\n",
    "            dtype=\"bool\",\n",
    "        )\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :], verbose=0,\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "# Use paths declared earlier\n",
    "# train_path = \"../../downloads/old_clips/full_res/train\"\n",
    "# test_path = \"../../downloads/old_clips/full_res/test\"\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, train_path)\n",
    "test_data, test_labels = prepare_all_videos(test_df, test_path)\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train model and return prediction score.\n",
    "# The scores are all mean accuracy except MLP regressor, which uses R^2\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Load handwritten digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Format X and y as np arrays\n",
    "X = train_data  # X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = train_labels   # y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Configure StratifiedKFold\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_mlp = []\n",
    "scores_mlp_regressor = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}\")\n",
    "    # print(f\"  Train: index={train_index}\")\n",
    "    # print(f\"  Test:  index={test_index}\")\n",
    "   \n",
    "    # Train LogisticRegression\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train SVC\n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train RandomForestClassifier\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLP\n",
    "    scores_mlp.append(get_score(MLPClassifier(random_state=1, max_iter=300), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLPRegressor (this one is slow)\n",
    "    scores_mlp_regressor.append(get_score(MLPRegressor(random_state=1, max_iter=500), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "\n",
    "# Print all scores\n",
    "model_names = [\"LogisticRegression\", \"SVC\", \"RandomForestClassifier\", \"MLPClassifier\", \"MLPRegressor\"]\n",
    "scores = [scores_logistic, scores_svm, scores_rf, scores_mlp, scores_mlp_regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    # x = keras.layers.Dense(8, activation=\"softmax\")(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"sigmoid\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "    \n",
    "    # opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        # loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/tmp/video_classifier/ckpt.weights.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/5\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 2.5246\n",
      "Epoch 1: val_loss improved from inf to 2.50697, saving model to /tmp/video_classifier/ckpt.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.0050 - loss: 2.5089 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 2/10\n",
      "\u001b[1m1/5\u001b[0m \u001b[32mâ”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0469 - loss: 2.4935\n",
      "Epoch 2: val_loss improved from 2.50697 to 2.50667, saving model to /tmp/video_classifier/ckpt.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 2.4870 - val_accuracy: 0.0000e+00 - val_loss: 2.5067\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0700 - loss: 2.4810\n",
      "Epoch 3: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0722 - loss: 2.4808 - val_accuracy: 0.0000e+00 - val_loss: 2.5069\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0888 - loss: 2.4714\n",
      "Epoch 4: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0916 - loss: 2.4713 - val_accuracy: 0.0000e+00 - val_loss: 2.5071\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1767 - loss: 2.4619\n",
      "Epoch 5: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1760 - loss: 2.4619 - val_accuracy: 0.0000e+00 - val_loss: 2.5077\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2318 - loss: 2.4577\n",
      "Epoch 6: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2320 - loss: 2.4574 - val_accuracy: 0.0000e+00 - val_loss: 2.5087\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2415 - loss: 2.4562\n",
      "Epoch 7: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2428 - loss: 2.4554 - val_accuracy: 0.0963 - val_loss: 2.5094\n",
      "Epoch 8/10\n",
      "\u001b[1m4/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”â”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2581 - loss: 2.4467\n",
      "Epoch 8: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2594 - loss: 2.4453 - val_accuracy: 0.0963 - val_loss: 2.5102\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3025 - loss: 2.4362\n",
      "Epoch 9: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3021 - loss: 2.4360 - val_accuracy: 0.0963 - val_loss: 2.5113\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3186 - loss: 2.4310\n",
      "Epoch 10: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3235 - loss: 2.4306 - val_accuracy: 0.0963 - val_loss: 2.5124\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0048 - loss: 2.4768   \n",
      "Test accuracy: 0.22%\n"
     ]
    }
   ],
   "source": [
    "_, sequence_model = run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: ../../downloads/test/Eating/7395553781087521937.mp4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "  Doctor Visit: 56.92%\n",
      "  Sitting In Wheelchair: 53.53%\n",
      "  Transfer To Bed: 50.68%\n",
      "  Talking on the Phone: 49.06%\n",
      "  EVS Visit: 47.47%\n",
      "  Asleep-Trying to sleep: 47.40%\n",
      "  Nurse Visit: 46.25%\n",
      "  Watching TV: 43.84%\n",
      "  Family: 43.70%\n",
      "  Lying In Bed: 41.84%\n",
      "  Eating: 41.83%\n",
      "  Therapy: 41.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(<unknown>:65618): GStreamer-CRITICAL **: 15:40:02.276: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@36291.277] global cap_gstreamer.cpp:1436 open OpenCV | GStreamer warning: Error opening bin: no element \"test\"\n",
      "[ WARN:0@36291.277] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "OpenCV: Couldn't read video stream from file \"test/../../downloads/test/Eating/7395553781087521937.mp4\"\n",
      "[ WARN:0@36291.280] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.10.0) /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_49s_p64pd6/croot/opencv-suite_1722029132360/work/modules/videoio/src/cap_images.cpp:274: error: (-215:Assertion failed) number < max_number in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(\n",
    "        shape=(\n",
    "            1,\n",
    "            MAX_SEQ_LENGTH,\n",
    "        ),\n",
    "        dtype=\"bool\",\n",
    "    )\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, duration=100)\n",
    "    return Image(\"animation.gif\")\n",
    "\n",
    "\n",
    "# train_path = f\"../../downloads/train\"\n",
    "# test_path = f\"../../downloads/test\"\n",
    "\n",
    "# train_data, train_labels = prepare_all_videos(train_df, train_path)\n",
    "# test_data, test_labels = prepare_all_videos(test_df, test_path)\n",
    "\n",
    "test_video = np.random.choice(test_df[\"path\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = sequence_prediction(test_video)\n",
    "# to_gif(test_frames[:MAX_SEQ_LENGTH])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
