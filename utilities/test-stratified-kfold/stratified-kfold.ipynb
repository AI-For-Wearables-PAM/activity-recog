{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test stratified k-fold cross validation\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "Fold 0:\n",
      "  Train: index=[1 3]\n",
      "  Test:  index=[0 2]\n",
      "Fold 1:\n",
      "  Train: index=[0 2]\n",
      "  Test:  index=[1 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([0, 0, 1, 1])\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example using stratified kfold on the digits dataset\n",
    "- Source: https://github.com/codebasics/py/blob/master/ML/12_KFold_Cross_Validation/12_k_fold.ipynb\n",
    "- Video tutorial: https://www.youtube.com/watch?v=gJo0uNL-5Qw  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
      "Fold 0\n",
      "Fold 1\n",
      "Fold 2\n",
      "Fold 3\n",
      "Fold 4\n"
     ]
    }
   ],
   "source": [
    "# Function to train model and return prediction score.\n",
    "# The scores are all mean accuracy except MLP regressor, which uses R^2\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "\n",
    "# Load handwritten digits dataset\n",
    "digits = load_digits()\n",
    "\n",
    "# Format X and y as np arrays\n",
    "X = digits.data  # X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = digits.target   # y = np.array([0, 0, 1, 1])\n",
    "\n",
    "# Configure StratifiedKFold\n",
    "num_folds = 5\n",
    "skf = StratifiedKFold(n_splits=num_folds)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "print(skf)\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "scores_mlp = []\n",
    "scores_mlp_regressor = []\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}\")\n",
    "    # print(f\"  Train: index={train_index}\")\n",
    "    # print(f\"  Test:  index={test_index}\")\n",
    "   \n",
    "    # Train LogisticRegression\n",
    "    scores_logistic.append(get_score(LogisticRegression(solver='liblinear',multi_class='ovr'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train SVC\n",
    "    scores_svm.append(get_score(SVC(gamma='auto'), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train RandomForestClassifier\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLP\n",
    "    scores_mlp.append(get_score(MLPClassifier(random_state=1, max_iter=300), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "    # Train MLPRegressor (this one is slow)\n",
    "    scores_mlp_regressor.append(get_score(MLPRegressor(random_state=1, max_iter=500), X[train_index], X[test_index], y[train_index], y[test_index]))\n",
    "\n",
    "\n",
    "# Print all scores\n",
    "model_names = [\"LogisticRegression\", \"SVC\", \"RandomForestClassifier\", \"MLPClassifier\", \"MLPRegressor\"]\n",
    "scores = [scores_logistic, scores_svm, scores_rf, scores_mlp, scores_mlp_regressor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.411111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.938889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.947222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.880556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.877778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1</td>\n",
       "      <td>0.809039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.952646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.454039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.955432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.972145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>2</td>\n",
       "      <td>0.789852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.448468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.958217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.961003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>MLPClassifier</td>\n",
       "      <td>3</td>\n",
       "      <td>0.865563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.894150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.479109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.922006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.896936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>MLPRegressor</td>\n",
       "      <td>4</td>\n",
       "      <td>0.783802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Fold     Score\n",
       "0       LogisticRegression     0  0.922222\n",
       "1       LogisticRegression     0  0.411111\n",
       "2       LogisticRegression     0  0.938889\n",
       "3       LogisticRegression     0  0.947222\n",
       "4       LogisticRegression     0  0.826025\n",
       "5                      SVC     1  0.883333\n",
       "6                      SVC     1  0.450000\n",
       "7                      SVC     1  0.880556\n",
       "8                      SVC     1  0.877778\n",
       "9                      SVC     1  0.809039\n",
       "10  RandomForestClassifier     2  0.952646\n",
       "11  RandomForestClassifier     2  0.454039\n",
       "12  RandomForestClassifier     2  0.955432\n",
       "13  RandomForestClassifier     2  0.972145\n",
       "14  RandomForestClassifier     2  0.789852\n",
       "15           MLPClassifier     3  0.958217\n",
       "16           MLPClassifier     3  0.448468\n",
       "17           MLPClassifier     3  0.958217\n",
       "18           MLPClassifier     3  0.961003\n",
       "19           MLPClassifier     3  0.865563\n",
       "20            MLPRegressor     4  0.894150\n",
       "21            MLPRegressor     4  0.479109\n",
       "22            MLPRegressor     4  0.922006\n",
       "23            MLPRegressor     4  0.896936\n",
       "24            MLPRegressor     4  0.783802"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make DataFrame scores to compare model performance\n",
    "all_models = []\n",
    "all_folds = []\n",
    "all_scores = []\n",
    "\n",
    "for i in enumerate(model_names):\n",
    "    for s in scores:\n",
    "        all_models.append(i[1])\n",
    "        all_folds.append(i[0])\n",
    "        all_scores.append(s[i[0]])\n",
    "\n",
    "# Make DataFrame of results\n",
    "data = {\"Model\": all_models, \"Fold\": all_folds, \"Score\": all_scores}\n",
    "scores_df = pd.DataFrame(data)\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify ImageNet classes with ResNet50\n",
    "https://keras.io/api/applications/#usage-examples-for-image-classification-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    "\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = keras.utils.load_img(img_path, target_size=(224, 224))\n",
    "x = keras.utils.img_to_array(img)\n",
    "x\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "# preds = model.predict(x)\n",
    "# # decode the results into a list of tuples (class, description, probability)\n",
    "# # (one such list for each sample in the batch)\n",
    "# print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicing Video frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: The video preprocessing method here may be useful\n",
    "\n",
    "Tutorial: https://keras.io/examples/vision/video_classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras\n",
    "import os\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "MAX_SEQ_LENGTH = 20\n",
    "NUM_FEATURES = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_to_frames(video_path, img_size=(64, 64), sequence_length=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # frame = cv2.resize(frame, img_size)\n",
    "        img = keras.utils.load_img(frame, target_size=(224, 224))\n",
    "        x = keras.utils.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        frames.append(x)\n",
    "        if len(frames) == sequence_length:\n",
    "            break\n",
    "    cap.release()\n",
    "\n",
    "    if len(frames) < sequence_length:\n",
    "        return None  # Ignore short videos\n",
    "\n",
    "    return np.array(frames)\n",
    "\n",
    "\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]\n",
    "\n",
    "\n",
    "def load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "\n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a CSV with video filenames and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List files and ignore .DS_Store if on a Mac\n",
    "def list_files(directory):\n",
    "    visible_files = []\n",
    "    for file in os.listdir(directory):\n",
    "        if not file.startswith('.'):\n",
    "            visible_files.append(file)\n",
    "\n",
    "    return visible_files\n",
    "\n",
    "def catalog_videos(folder_path):\n",
    "    # classes = os.listdir(folder_path)\n",
    "    classes = list_files(folder_path)\n",
    "    videos, labels, encoded_labels, paths = [], [], [], []\n",
    "\n",
    "    for label, activity in enumerate(classes):\n",
    "        activity_folder = os.path.join(folder_path, activity)\n",
    "        # for video_file in os.listdir(activity_folder):\n",
    "        for video_file in list_files(activity_folder):\n",
    "            video_path = os.path.join(activity_folder, video_file)\n",
    "            videos.append(video_file)\n",
    "            labels.append(activity)\n",
    "            encoded_labels.append(label)\n",
    "            paths.append(video_path)\n",
    "\n",
    "    # Encode labels\n",
    "    le = LabelEncoder()\n",
    "    le.fit(labels)\n",
    "    le.transform(labels)\n",
    "\n",
    "    return videos, labels, encoded_labels, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_feature_extractor():\n",
    "    feature_extractor = keras.applications.InceptionV3(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "    )\n",
    "    preprocess_input = keras.applications.inception_v3.preprocess_input\n",
    "\n",
    "    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n",
    "    preprocessed = preprocess_input(inputs)\n",
    "\n",
    "    outputs = feature_extractor(preprocessed)\n",
    "    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n",
    "\n",
    "\n",
    "feature_extractor = build_feature_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_catalog_csv(path, name):\n",
    "    # Create catalog of dataset details\n",
    "    catalog = catalog_videos(path)\n",
    "\n",
    "    # Make dataframe\n",
    "    df = pd.DataFrame({'video': catalog[0], 'label': catalog[1],\n",
    "                            'encoded_label': catalog[2], 'path': catalog[3]})\n",
    "    # Export CSV\n",
    "    filename = f'{name}.csv'\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f'Saved to {filename}')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'catalog_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../downloads/old_clips/resized/train_resized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m test_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../downloads/old_clips/resized/test_resized\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m train_df \u001b[38;5;241m=\u001b[39m make_catalog_csv(train_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_df\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m test_df \u001b[38;5;241m=\u001b[39m make_catalog_csv(test_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_df\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[77], line 3\u001b[0m, in \u001b[0;36mmake_catalog_csv\u001b[0;34m(path, name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_catalog_csv\u001b[39m(path, name):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Create catalog of dataset details\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     catalog \u001b[38;5;241m=\u001b[39m catalog_videos(path)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Make dataframe\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo\u001b[39m\u001b[38;5;124m'\u001b[39m: catalog[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m: catalog[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m      7\u001b[0m                             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoded_label\u001b[39m\u001b[38;5;124m'\u001b[39m: catalog[\u001b[38;5;241m2\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m'\u001b[39m: catalog[\u001b[38;5;241m3\u001b[39m]})\n",
      "\u001b[0;31mNameError\u001b[0m: name 'catalog_videos' is not defined"
     ]
    }
   ],
   "source": [
    "# Make CSV for training/testing sets\n",
    "# train_path = \"../../downloads/old_clips/full_res/train\"\n",
    "# test_path = \"../../downloads/old_clips/full_res/test\"\n",
    "train_path = \"../../downloads/old_clips/resized/train_resized\"\n",
    "test_path = \"../../downloads/old_clips/resized/test_resized\"\n",
    "\n",
    "train_df = make_catalog_csv(train_path, \"train_df\")\n",
    "test_df = make_catalog_csv(test_path, \"test_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video</th>\n",
       "      <th>label</th>\n",
       "      <th>encoded_label</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7394376070990187665_r.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7394375134687317137_r.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7394377634358283409_r.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7394377110372273297_r.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7394376363047963793_r.mp4</td>\n",
       "      <td>EVS Visit</td>\n",
       "      <td>0</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>7395162737200123025_r.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>7394439481887345809_r.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>7393864218262686865_r.mp4</td>\n",
       "      <td>Nurse Visit</td>\n",
       "      <td>10</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>7393435193979489425_r.mp4</td>\n",
       "      <td>Transfer To Bed</td>\n",
       "      <td>11</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>7393687927035055249_r.mp4</td>\n",
       "      <td>Transfer To Bed</td>\n",
       "      <td>11</td>\n",
       "      <td>../../downloads/old_clips/resized/test_resized...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         video            label  encoded_label  \\\n",
       "0    7394376070990187665_r.mp4        EVS Visit              0   \n",
       "1    7394375134687317137_r.mp4        EVS Visit              0   \n",
       "2    7394377634358283409_r.mp4        EVS Visit              0   \n",
       "3    7394377110372273297_r.mp4        EVS Visit              0   \n",
       "4    7394376363047963793_r.mp4        EVS Visit              0   \n",
       "..                         ...              ...            ...   \n",
       "441  7395162737200123025_r.mp4      Nurse Visit             10   \n",
       "442  7394439481887345809_r.mp4      Nurse Visit             10   \n",
       "443  7393864218262686865_r.mp4      Nurse Visit             10   \n",
       "444  7393435193979489425_r.mp4  Transfer To Bed             11   \n",
       "445  7393687927035055249_r.mp4  Transfer To Bed             11   \n",
       "\n",
       "                                                  path  \n",
       "0    ../../downloads/old_clips/resized/test_resized...  \n",
       "1    ../../downloads/old_clips/resized/test_resized...  \n",
       "2    ../../downloads/old_clips/resized/test_resized...  \n",
       "3    ../../downloads/old_clips/resized/test_resized...  \n",
       "4    ../../downloads/old_clips/resized/test_resized...  \n",
       "..                                                 ...  \n",
       "441  ../../downloads/old_clips/resized/test_resized...  \n",
       "442  ../../downloads/old_clips/resized/test_resized...  \n",
       "443  ../../downloads/old_clips/resized/test_resized...  \n",
       "444  ../../downloads/old_clips/resized/test_resized...  \n",
       "445  ../../downloads/old_clips/resized/test_resized...  \n",
       "\n",
       "[446 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Asleep-Trying to sleep', 'Doctor Visit', 'EVS Visit', 'Eating', 'Family', 'Lying In Bed', 'Nurse Visit', 'Sitting In Wheelchair', 'Talking on the Phone', 'Therapy', 'Transfer To Bed', 'Watching TV']\n"
     ]
    }
   ],
   "source": [
    "label_processor = keras.layers.StringLookup(\n",
    "    num_oov_indices=0, vocabulary=np.unique(train_df[\"label\"])\n",
    ")\n",
    "print(label_processor.get_vocabulary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def prepare_all_videos(df, root_dir):\n",
    "    num_samples = len(df)\n",
    "    video_paths = df[\"path\"].values.tolist()\n",
    "    labels = df[\"label\"].values\n",
    "    labels = keras.ops.convert_to_numpy(label_processor(labels[..., None]))\n",
    "\n",
    "    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n",
    "    # `frame_masks` will contain a bunch of booleans denoting if a timestep is\n",
    "    # masked with padding or not.\n",
    "    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")\n",
    "    frame_features = np.zeros(\n",
    "        shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "    )\n",
    "\n",
    "    # For each video.\n",
    "    for idx, path in enumerate(video_paths):\n",
    "        # Gather all its frames and add a batch dimension.\n",
    "        # frames = load_video(os.path.join(root_dir, path))\n",
    "        frames = load_video(path)\n",
    "        frames = frames[None, ...]\n",
    "\n",
    "        # Initialize placeholders to store the masks and features of the current video.\n",
    "        temp_frame_mask = np.zeros(\n",
    "            shape=(\n",
    "                1,\n",
    "                MAX_SEQ_LENGTH,\n",
    "            ),\n",
    "            dtype=\"bool\",\n",
    "        )\n",
    "        temp_frame_features = np.zeros(\n",
    "            shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\"\n",
    "        )\n",
    "\n",
    "        # Extract features from the frames of the current video.\n",
    "        for i, batch in enumerate(frames):\n",
    "            video_length = batch.shape[0]\n",
    "            length = min(MAX_SEQ_LENGTH, video_length)\n",
    "            for j in range(length):\n",
    "                temp_frame_features[i, j, :] = feature_extractor.predict(\n",
    "                    batch[None, j, :], verbose=0,\n",
    "                )\n",
    "            temp_frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "        frame_features[idx,] = temp_frame_features.squeeze()\n",
    "        frame_masks[idx,] = temp_frame_mask.squeeze()\n",
    "\n",
    "    return (frame_features, frame_masks), labels\n",
    "\n",
    "# Use paths declared earlier\n",
    "# train_path = \"../../downloads/old_clips/full_res/train\"\n",
    "# test_path = \"../../downloads/old_clips/full_res/test\"\n",
    "\n",
    "train_data, train_labels = prepare_all_videos(train_df, train_path)\n",
    "test_data, test_labels = prepare_all_videos(test_df, test_path)\n",
    "\n",
    "print(f\"Frame features in train set: {train_data[0].shape}\")\n",
    "print(f\"Frame masks in train set: {train_data[1].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def get_score(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)\n",
    "\n",
    "# X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "# y = np.array([0, 0, 1, 1])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2)\n",
    "skf.get_n_splits(X, y)\n",
    "\n",
    "\n",
    "scores_logistic = []\n",
    "scores_svm = []\n",
    "scores_rf = []\n",
    "\n",
    "for train_index, test_index in folds.split(digits.data,digits.target):\n",
    "    X_train, X_test, y_train, y_test = digits.data[train_index], digits.data[test_index], \\\n",
    "                                       digits.target[train_index], digits.target[test_index]\n",
    "\n",
    "print(skf)\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"  Train: index={train_index}\")\n",
    "    print(f\"  Test:  index={test_index}\")\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(digits.data,digits.target,test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility for our sequence model.\n",
    "def get_sequence_model():\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n",
    "    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n",
    "\n",
    "    # Refer to the following tutorial to understand the significance of using `mask`:\n",
    "    # https://keras.io/api/layers/recurrent_layers/gru/\n",
    "    x = keras.layers.GRU(16, return_sequences=True)(\n",
    "        frame_features_input, mask=mask_input\n",
    "    )\n",
    "    x = keras.layers.GRU(8)(x)\n",
    "    x = keras.layers.Dropout(0.5)(x)\n",
    "    # x = keras.layers.Dense(8, activation=\"softmax\")(x)\n",
    "    x = keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    output = keras.layers.Dense(len(class_vocab), activation=\"sigmoid\")(x)\n",
    "\n",
    "    rnn_model = keras.Model([frame_features_input, mask_input], output)\n",
    "    \n",
    "    # opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "    rnn_model.compile(\n",
    "        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
    "        # loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return rnn_model\n",
    "\n",
    "\n",
    "# Utility for running experiments.\n",
    "def run_experiment():\n",
    "    filepath = \"/tmp/video_classifier/ckpt.weights.h5\"\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        filepath, save_weights_only=True, save_best_only=True, verbose=1\n",
    "    )\n",
    "\n",
    "    seq_model = get_sequence_model()\n",
    "    history = seq_model.fit(\n",
    "        [train_data[0], train_data[1]],\n",
    "        train_labels,\n",
    "        validation_split=0.3,\n",
    "        epochs=EPOCHS,\n",
    "        callbacks=[checkpoint],\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    seq_model.load_weights(filepath)\n",
    "    _, accuracy = seq_model.evaluate([test_data[0], test_data[1]], test_labels)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history, seq_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.0000e+00 - loss: 2.5246\n",
      "Epoch 1: val_loss improved from inf to 2.50697, saving model to /tmp/video_classifier/ckpt.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - accuracy: 0.0050 - loss: 2.5089 - val_accuracy: 0.0000e+00 - val_loss: 2.5070\n",
      "Epoch 2/10\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0469 - loss: 2.4935\n",
      "Epoch 2: val_loss improved from 2.50697 to 2.50667, saving model to /tmp/video_classifier/ckpt.weights.h5\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0341 - loss: 2.4870 - val_accuracy: 0.0000e+00 - val_loss: 2.5067\n",
      "Epoch 3/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0700 - loss: 2.4810\n",
      "Epoch 3: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0722 - loss: 2.4808 - val_accuracy: 0.0000e+00 - val_loss: 2.5069\n",
      "Epoch 4/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.0888 - loss: 2.4714\n",
      "Epoch 4: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0916 - loss: 2.4713 - val_accuracy: 0.0000e+00 - val_loss: 2.5071\n",
      "Epoch 5/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.1767 - loss: 2.4619\n",
      "Epoch 5: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1760 - loss: 2.4619 - val_accuracy: 0.0000e+00 - val_loss: 2.5077\n",
      "Epoch 6/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2318 - loss: 2.4577\n",
      "Epoch 6: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.2320 - loss: 2.4574 - val_accuracy: 0.0000e+00 - val_loss: 2.5087\n",
      "Epoch 7/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2415 - loss: 2.4562\n",
      "Epoch 7: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2428 - loss: 2.4554 - val_accuracy: 0.0963 - val_loss: 2.5094\n",
      "Epoch 8/10\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2581 - loss: 2.4467\n",
      "Epoch 8: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2594 - loss: 2.4453 - val_accuracy: 0.0963 - val_loss: 2.5102\n",
      "Epoch 9/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3025 - loss: 2.4362\n",
      "Epoch 9: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.3021 - loss: 2.4360 - val_accuracy: 0.0963 - val_loss: 2.5113\n",
      "Epoch 10/10\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3186 - loss: 2.4310\n",
      "Epoch 10: val_loss did not improve from 2.50667\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.3235 - loss: 2.4306 - val_accuracy: 0.0963 - val_loss: 2.5124\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0048 - loss: 2.4768   \n",
      "Test accuracy: 0.22%\n"
     ]
    }
   ],
   "source": [
    "_, sequence_model = run_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test video path: ../../downloads/test/Eating/7395553781087521937.mp4\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "  Doctor Visit: 56.92%\n",
      "  Sitting In Wheelchair: 53.53%\n",
      "  Transfer To Bed: 50.68%\n",
      "  Talking on the Phone: 49.06%\n",
      "  EVS Visit: 47.47%\n",
      "  Asleep-Trying to sleep: 47.40%\n",
      "  Nurse Visit: 46.25%\n",
      "  Watching TV: 43.84%\n",
      "  Family: 43.70%\n",
      "  Lying In Bed: 41.84%\n",
      "  Eating: 41.83%\n",
      "  Therapy: 41.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(<unknown>:65618): GStreamer-CRITICAL **: 15:40:02.276: gst_element_make_from_uri: assertion 'gst_uri_is_valid (uri)' failed\n",
      "[ WARN:0@36291.277] global cap_gstreamer.cpp:1436 open OpenCV | GStreamer warning: Error opening bin: no element \"test\"\n",
      "[ WARN:0@36291.277] global cap_gstreamer.cpp:1173 isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "OpenCV: Couldn't read video stream from file \"test/../../downloads/test/Eating/7395553781087521937.mp4\"\n",
      "[ WARN:0@36291.280] global cap.cpp:166 open VIDEOIO(CV_IMAGES): raised OpenCV exception:\n",
      "\n",
      "OpenCV(4.10.0) /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_49s_p64pd6/croot/opencv-suite_1722029132360/work/modules/videoio/src/cap_images.cpp:274: error: (-215:Assertion failed) number < max_number in function 'icvExtractPattern'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def prepare_single_video(frames):\n",
    "    frames = frames[None, ...]\n",
    "    frame_mask = np.zeros(\n",
    "        shape=(\n",
    "            1,\n",
    "            MAX_SEQ_LENGTH,\n",
    "        ),\n",
    "        dtype=\"bool\",\n",
    "    )\n",
    "    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n",
    "\n",
    "    for i, batch in enumerate(frames):\n",
    "        video_length = batch.shape[0]\n",
    "        length = min(MAX_SEQ_LENGTH, video_length)\n",
    "        for j in range(length):\n",
    "            frame_features[i, j, :] = feature_extractor.predict(batch[None, j, :])\n",
    "        frame_mask[i, :length] = 1  # 1 = not masked, 0 = masked\n",
    "\n",
    "    return frame_features, frame_mask\n",
    "\n",
    "\n",
    "def sequence_prediction(path):\n",
    "    class_vocab = label_processor.get_vocabulary()\n",
    "\n",
    "    frames = load_video(os.path.join(\"test\", path))\n",
    "    frame_features, frame_mask = prepare_single_video(frames)\n",
    "    probabilities = sequence_model.predict([frame_features, frame_mask])[0]\n",
    "\n",
    "    for i in np.argsort(probabilities)[::-1]:\n",
    "        print(f\"  {class_vocab[i]}: {probabilities[i] * 100:5.2f}%\")\n",
    "    return frames\n",
    "\n",
    "\n",
    "# This utility is for visualization.\n",
    "# Referenced from:\n",
    "# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\n",
    "def to_gif(images):\n",
    "    converted_images = images.astype(np.uint8)\n",
    "    imageio.mimsave(\"animation.gif\", converted_images, duration=100)\n",
    "    return Image(\"animation.gif\")\n",
    "\n",
    "\n",
    "# train_path = f\"../../downloads/train\"\n",
    "# test_path = f\"../../downloads/test\"\n",
    "\n",
    "# train_data, train_labels = prepare_all_videos(train_df, train_path)\n",
    "# test_data, test_labels = prepare_all_videos(test_df, test_path)\n",
    "\n",
    "test_video = np.random.choice(test_df[\"path\"].values.tolist())\n",
    "print(f\"Test video path: {test_video}\")\n",
    "test_frames = sequence_prediction(test_video)\n",
    "# to_gif(test_frames[:MAX_SEQ_LENGTH])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
